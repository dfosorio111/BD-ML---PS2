data$Dominio <- as.factor(data$Dominio)
data$P5090 <- as.factor(data$P5090)
data$Depto <- as.factor(data$Depto)
#Ojo con esta variable, hay varios 98 y 99 que podrían asignarse mejor con KNN
data$jefe_mujer <- as.factor(data$jefe_mujer)
data$P6090 <- as.factor(data$P6090)
#Recordar que esta es afiliación a seguridad social en salud
data$jefe_cotiza <- as.factor(data$jefe_cotiza)
data$relab_jefe <- as.factor(data$relab_jefe)
data$max_edu_lev_h <- as.factor(data$max_edu_lev_h)
data$max_empl<- as.factor(data$max_empl)
data$Relab1 <- as.factor(data$Relab1)
data$Relab2 <- as.factor(data$Relab2)
data$Relab3 <- as.factor(data$Relab3)
data$Educ1 <- as.factor(data$Educ1)
data$Educ2 <- as.factor(data$Educ2)
data$Educ3 <- as.factor(data$Educ3)
data$hijos <- as.factor(data$hijos)
data$pareja <- as.factor(data$pareja)
data$nietos <- as.factor(data$nietos)
data$otros_parientes <- as.factor(data$otros_parientes)
data$no_parientes <- as.factor(data$no_parientes)
data$emp_pen <- as.factor(data$emp_pen)
data$prop_cotiza <- data$Cant_cotiza_recibe/data$Num_pet_hogar
names(data)
data <- data[c("Lp","Pobre", "Clase", "jefe_mujer", "max_edu_lev_h", "max_empl", "Horas_Hogar", "P6040", "age2", "prop_ocupados_pet", "relab_jefe", "prop_cotiza", "Ingpcug", "Valor_Arriendo")]
#Se crea la matriz que le gusta a Ignacio
df <- model.matrix(~ .  - 1, data)
# Dividimos train/test (70/30)
n <- nrow(df)
smp_size <- floor(0.7*n)
train_ind <- sample(1:n, size = smp_size)
train <- df[train_ind, ]
test <- df[-train_ind, ]
# Estandarizamos DESPUÉS de partir la base en train/test
variables_numericas <- c( "P6040", "Horas_Hogar",
"prop_ocupados_pet", "age2", "prop_cotiza", "Valor_Arriendo")
escalador <- preProcess(train[, variables_numericas])
train_s <- train
test_s <- test
train_s[, variables_numericas] <- predict(escalador, train[, variables_numericas])
test_s[, variables_numericas] <- predict(escalador, test[, variables_numericas])
train_s <- data.frame(train_s)
test_s <- data.frame(test_s)
train <- data.frame(train)
test <- data.frame(test)
#Iniciamos con la regresión lineal
names(train_s)
modelo1 <- lm(formula = Ingpcug ~ . -1-Lp-Pobre, data = train_s)
insample1 <- predict(modelo1, train_s)
train_s$prediccion <- insample1
train_s$pobre_lm <- ifelse(train_s$prediccion <= train_s$Lp, 1, 0)
tabla_lm <- train_s%>%select(Pobre, pobre_lm)%>%table()
cm_lm <- confusionMatrix(data=factor(train_s$pobre_lm) ,
reference=factor(train_s$Pobre) ,
mode="sens_spec" , positive="1")
cm_lm
#En este modelo el sesnsitivity es super bueno (0.84), pero tenemos un specificty terrible y un accuracy bajo
Agregado_lm <- cm_lm$byClass[[1]]*0.75 +cm_lm$byClass[[2]]*0.25
Agregado_lm
data <- read.csv("train_completa.csv")
names(data)
data$Valor_Arriendo <- ifelse(is.na(data$P5130),data$P5140, data$P5130)
data <- data[-c(1:3,10:12,15,17,19)]
#Las variables que son factores ponerlas como factores
names(data)
data$age2 <- data$P6040^2
#data$age_mujer <- data$P6040*data$jefe_mujer
#data$age2_mujer <- data$age2*data$jefe_mujer
data$Clase <- as.factor(data$Clase)
data$Dominio <- as.factor(data$Dominio)
data$P5090 <- as.factor(data$P5090)
data$Depto <- as.factor(data$Depto)
#Ojo con esta variable, hay varios 98 y 99 que podrían asignarse mejor con KNN
data$jefe_mujer <- as.factor(data$jefe_mujer)
data$P6090 <- as.factor(data$P6090)
#Recordar que esta es afiliación a seguridad social en salud
data$jefe_cotiza <- as.factor(data$jefe_cotiza)
data$relab_jefe <- as.factor(data$relab_jefe)
data$max_edu_lev_h <- as.factor(data$max_edu_lev_h)
data$max_empl<- as.factor(data$max_empl)
data$Relab1 <- as.factor(data$Relab1)
data$Relab2 <- as.factor(data$Relab2)
data$Relab3 <- as.factor(data$Relab3)
data$Educ1 <- as.factor(data$Educ1)
data$Educ2 <- as.factor(data$Educ2)
data$Educ3 <- as.factor(data$Educ3)
data$hijos <- as.factor(data$hijos)
data$pareja <- as.factor(data$pareja)
data$nietos <- as.factor(data$nietos)
data$otros_parientes <- as.factor(data$otros_parientes)
data$no_parientes <- as.factor(data$no_parientes)
data$emp_pen <- as.factor(data$emp_pen)
data$prop_cotiza <- data$Cant_cotiza_recibe/data$Num_pet_hogar
names(data)
data <- data[c("Lp","Pobre", "Clase", "jefe_mujer", "max_edu_lev_h", "max_empl", "Horas_Hogar", "P6040", "age2", "prop_ocupados_pet", "relab_jefe", "prop_cotiza", "Ingpcug", "Valor_Arriendo", "Relab2", "nietos", "no_parientes", "otros_parientes", "prop_mujeres_pet")]
#Se crea la matriz que le gusta a Ignacio
df <- model.matrix(~ .  - 1, data)
# Dividimos train/test (70/30)
n <- nrow(df)
smp_size <- floor(0.7*n)
train_ind <- sample(1:n, size = smp_size)
train <- df[train_ind, ]
test <- df[-train_ind, ]
# Estandarizamos DESPUÉS de partir la base en train/test
variables_numericas <- c( "P6040", "Horas_Hogar",
"prop_ocupados_pet", "age2", "prop_cotiza", "Valor_Arriendo")
escalador <- preProcess(train[, variables_numericas])
train_s <- train
test_s <- test
train_s[, variables_numericas] <- predict(escalador, train[, variables_numericas])
test_s[, variables_numericas] <- predict(escalador, test[, variables_numericas])
train_s <- data.frame(train_s)
test_s <- data.frame(test_s)
train <- data.frame(train)
test <- data.frame(test)
#Iniciamos con la regresión lineal
names(train_s)
modelo1 <- lm(formula = Ingpcug ~ . -1-Lp-Pobre, data = train_s)
insample1 <- predict(modelo1, train_s)
train_s$prediccion <- insample1
train_s$pobre_lm <- ifelse(train_s$prediccion <= train_s$Lp, 1, 0)
tabla_lm <- train_s%>%select(Pobre, pobre_lm)%>%table()
cm_lm <- confusionMatrix(data=factor(train_s$pobre_lm) ,
reference=factor(train_s$Pobre) ,
mode="sens_spec" , positive="1")
cm_lm
#En este modelo el sesnsitivity es bajo(0.52), pero tenemos un specificty bueno (0.89) y un accuracy decennte (0.81)
Agregado_lm <- cm_lm$byClass[[1]]*0.75 +cm_lm$byClass[[2]]*0.25
Agregado_lm
#Logit
logit <- glm(formula = factor(Pobre) ~ . - 1- Lp - Ingpcug, family=binomial(link="logit") , data=train_s)
train_s$pobre_log <- predict(logit , newdata=train_s , type="response")
rule <- 0.5
train_s$pred_log <- ifelse(train_s$pobre_log >= rule, 1, 0)
tabla_log <- train_s%>%select(Pobre, pred_log)%>%table()
tabla_log
cm_log <- confusionMatrix(data=factor(train_s$pred_log) ,
reference=factor(train_s$Pobre) ,
mode="sens_spec" , positive="1")
cm_log
## La segunda parte continua en:
browseURL("https://eduard-martinez.github.io/teaching/big-data/week-04_2.txt")
####Lasso y Ridge para el lineal
names[train_s]
####Lasso y Ridge para el lineal
names(train_s)
train_s <- data.frame(train_s)
test_s <- data.frame(test_s)
train <- data.frame(train)
test <- data.frame(test)
names(train_s)
n <- nrow(df)
smp_size <- floor(0.7*n)
train_ind <- sample(1:n, size = smp_size)
train <- df[train_ind, ]
test <- df[-train_ind, ]
# Estandarizamos DESPUÉS de partir la base en train/test
variables_numericas <- c( "P6040", "Horas_Hogar",
"prop_ocupados_pet", "age2", "prop_cotiza", "Valor_Arriendo")
escalador <- preProcess(train[, variables_numericas])
train_s <- train
test_s <- test
train_s[, variables_numericas] <- predict(escalador, train[, variables_numericas])
test_s[, variables_numericas] <- predict(escalador, test[, variables_numericas])
train_s <- data.frame(train_s)
test_s <- data.frame(test_s)
train <- data.frame(train)
test <- data.frame(test)
names(train_s)
X_train <- select(train, -c("Ingpcug", "Lp", "Pobre"))
y_train <- train_s[,"Ingpcug"])
y_train <- train_s[,"Ingpcug"]
y_train
X_train
modelo_ridge <- glmnet(
x = X_train,
y = y_train,
alpha = 0,
nlambda = 300,
standardize = FALSE
)
p_load(tidyverse, rvest, data.table, dplyr, skimr, caret, rio,
vtable, stargazer, ggplot2, boot, MLmetrics, lfe,
tidyverse, fabricatr, stargazer, Hmisc, writexl, viridis, here,
modelsummary, # tidy, msummary
gamlr,        # cv.gamlr
ROCR, # ROC curve
class, glmnet)
modelo_ridge <- glmnet(
x = X_train,
y = y_train,
alpha = 0,
nlambda = 300,
standardize = FALSE
)
View(modelo_ridge)
predicciones <- df()
predicciones <- data.frame()
predicciones$Real <- train_s$Pobre
predicciones <- train_s$Pobre
predicciones$IngReal <- train_s$Ingpcug
predicciones <- train_s$Pobre
predicciones <- cbind(predicciones,train_s$Ingpcug)
predicciones <- as.data.frame(predicciones)
View(predicciones)
colnames(predicciones) <- c("PobrezaReal", "IngpcReal")
View(predicciones)
predicciones <- cbind(predicciones,train_s$Ingpcug, train_s$Lp)
predicciones <- as.data.frame(predicciones)
colnames(predicciones) <- c("PobrezaReal", "IngpcReal", "Lp")
predicciones <- train_s$Pobre
predicciones <- cbind(predicciones,train_s$Ingpcug, train_s$Lp)
predicciones <- as.data.frame(predicciones)
colnames(predicciones) <- c("PobrezaReal", "IngpcReal", "Lp")
View(predicciones)
data <- read.csv("train_completa.csv")
names(data)
data$Valor_Arriendo <- ifelse(is.na(data$P5130),data$P5140, data$P5130)
data <- data[-c(1:3,10:12,15,17,19)]
#Las variables que son factores ponerlas como factores
names(data)
data$age2 <- data$P6040^2
#data$age_mujer <- data$P6040*data$jefe_mujer
#data$age2_mujer <- data$age2*data$jefe_mujer
data$Clase <- as.factor(data$Clase)
data$Dominio <- as.factor(data$Dominio)
data$P5090 <- as.factor(data$P5090)
data$Depto <- as.factor(data$Depto)
#Ojo con esta variable, hay varios 98 y 99 que podrían asignarse mejor con KNN
data$jefe_mujer <- as.factor(data$jefe_mujer)
data$P6090 <- as.factor(data$P6090)
#Recordar que esta es afiliación a seguridad social en salud
data$jefe_cotiza <- as.factor(data$jefe_cotiza)
data$relab_jefe <- as.factor(data$relab_jefe)
data$max_edu_lev_h <- as.factor(data$max_edu_lev_h)
data$max_empl<- as.factor(data$max_empl)
data$Relab1 <- as.factor(data$Relab1)
data$Relab2 <- as.factor(data$Relab2)
data$Relab3 <- as.factor(data$Relab3)
data$Educ1 <- as.factor(data$Educ1)
data$Educ2 <- as.factor(data$Educ2)
data$Educ3 <- as.factor(data$Educ3)
data$hijos <- as.factor(data$hijos)
data$pareja <- as.factor(data$pareja)
data$nietos <- as.factor(data$nietos)
data$otros_parientes <- as.factor(data$otros_parientes)
data$no_parientes <- as.factor(data$no_parientes)
data$emp_pen <- as.factor(data$emp_pen)
data$prop_cotiza <- data$Cant_cotiza_recibe/data$Num_pet_hogar
names(data)
is.na(data$P5090)%>%table()
data$ppc <- data$P5010/data$Nper
plot(data$ppc, data$Ingpcug)
plot(data$ppc, log(data$Ingpcug))
data$ppc <- data$Nper/data$P5010
plot(data$ppc, log(data$Ingpcug))
data <- data[c("Lp","Pobre", "Clase", "jefe_mujer", "max_edu_lev_h", "max_empl", "Horas_Hogar", "P6040", "age2", "prop_ocupados_pet", "relab_jefe", "prop_cotiza", "Ingpcug", "Valor_Arriendo", "Relab2", "nietos", "no_parientes", "otros_parientes", "prop_mujeres_pet", "ppc", "P5090")]
#Se crea la matriz que le gusta a Ignacio
df <- model.matrix(~ .  - 1, data)
# Dividimos train/test (70/30)
n <- nrow(df)
smp_size <- floor(0.7*n)
train_ind <- sample(1:n, size = smp_size)
train <- df[train_ind, ]
test <- df[-train_ind, ]
# Estandarizamos DESPUÉS de partir la base en train/test
variables_numericas <- c( "P6040", "Horas_Hogar",
"prop_ocupados_pet", "age2", "prop_cotiza", "Valor_Arriendo")
escalador <- preProcess(train[, variables_numericas])
train_s <- train
test_s <- test
train_s[, variables_numericas] <- predict(escalador, train[, variables_numericas])
test_s[, variables_numericas] <- predict(escalador, test[, variables_numericas])
train_s <- data.frame(train_s)
test_s <- data.frame(test_s)
train <- data.frame(train)
test <- data.frame(test)
names(train_s)
y_train <- train_s[,"Ingpcug"]
X_train <- select(train, -c("Ingpcug", "Lp", "Pobre"))
#Iniciamos con la regresión lineal
names(train_s)
modelo1 <- lm(formula = Ingpcug ~ . -1-Lp-Pobre, data = train_s)
insample1 <- predict(modelo1, train_s)
train_s$prediccion <- insample1
train_s$pobre_lm <- ifelse(train_s$prediccion <= train_s$Lp, 1, 0)
tabla_lm <- train_s%>%select(Pobre, pobre_lm)%>%table()
cm_lm <- confusionMatrix(data=factor(train_s$pobre_lm) ,
reference=factor(train_s$Pobre) ,
mode="sens_spec" , positive="1")
cm_lm
#En este modelo el sesnsitivity es bajo(0.53), pero tenemos un specificty bueno (0.89) y un accuracy decennte (0.82)
Agregado_lm <- cm_lm$byClass[[1]]*0.75 +cm_lm$byClass[[2]]*0.25
logit <- glm(formula = factor(Pobre) ~ . - 1- Lp - Ingpcug, family=binomial(link="logit") , data=train_s)
tidy(logit)
train_s$pobre_log <- predict(logit , newdata=train_s , type="response")
rule <- 0.5
train_s$pred_log <- ifelse(train_s$pobre_log >= rule, 1, 0)
tabla_log <- train_s%>%select(Pobre, pred_log)%>%table()
cm_log <- confusionMatrix(data=factor(train_s$pred_log) ,
reference=factor(train_s$Pobre) ,
mode="sens_spec" , positive="1")
cm_log
Agregado_log <- cm_log$byClass[[1]]*0.75 +cm_log$byClass[[2]]*0.25
View(X_train)
ggplot(data = data, aes(x = factor(Pobre), y = ppc))+
geom_boxplot()
modelo_ridge <- glmnet(
x = X_train,
y = y_train,
alpha = 0,
nlambda = 300,
standardize = FALSE
)
predicciones <- train_s$Pobre
predicciones <- cbind(predicciones,train_s$Ingpcug, train_s$Lp)
predicciones <- as.data.frame(predicciones)
colnames(predicciones) <- c("PobrezaReal", "IngpcReal", "Lp")
View(predicciones)
predicciones$ridge <- predict(modelo_ridge,
newx = as.matrix(X_train))
View(predicciones)
View(predicciones)
predicciones <- train_s$Pobre
predicciones <- cbind(predicciones,train_s$Ingpcug, train_s$Lp)
predicciones <- as.data.frame(predicciones)
colnames(predicciones) <- c("PobrezaReal", "IngpcReal", "Lp")
View(predicciones)
predicciones_ridge <- predict(modelo_ridge,
newx = as.matrix(X_train))
View(predicciones_ridge)
predicciones_ridge
y_train
modelo_ridge$lambda
lambdas_ridge <- modelo_ridge$lambda
resultados_ridge <- data.frame()
for (i in 1:length(lambdas_ridge)) {
l <- lambdas_ridge[i]
y_hat_out3 <- predicciones_ridge[, i]
r23 <- R2_Score(y_pred = y_hat_out3, y_true = y_test)
rmse3 <- RMSE(y_pred = y_hat_out3, y_true = y_test)
resultado <- data.frame(Modelo = "Ridge",
Muestra = "Fuera",
Lambda = l,
R2_Score = r23,
RMSE = rmse3)
resultados_ridge <- bind_rows(resultados_ridge, resultado)
}
for (i in 1:length(lambdas_ridge)) {
l <- lambdas_ridge[i]
y_hat_out3 <- predicciones_ridge[, i]
r23 <- R2_Score(y_pred = y_hat_out3, y_true = y_train)
rmse3 <- RMSE(y_pred = y_hat_out3, y_true = y_train)
resultado <- data.frame(Modelo = "Ridge",
Muestra = "Fuera",
Lambda = l,
R2_Score = r23,
RMSE = rmse3)
resultados_ridge <- bind_rows(resultados_ridge, resultado)
}
ggplot(resultados_ridge, aes(x = Lambda, y = RMSE)) +
geom_point() +
geom_line() +
theme_test() +
scale_y_continuous(labels = scales::comma)
ggplot(resultados_ridge, aes(x = Lambda, y = R2_Score)) +
geom_point() +
geom_line() +
theme_test() +
scale_y_continuous(labels = scales::comma)
filtro <- resultados_ridge$RMSE == min(resultados_ridge$RMSE)
filtro
mejor_lambda_ridge <- resultados_ridge[filtro, "Lambda"]
mejor_lambda_ridge
resultados_ridge$RMSE
# Guardamos el mejor Ridge
y_hat_in3 <- predict.glmnet(modelo_ridge,
newx = as.matrix(X_train),
s = mejor_lambda_ridge)
y_hat_in3
y_hat_in3%>%head()
y_pobre <- ifelse(y_hat_in3 <= predicciones$Lp, 1, 0)
y_pobre
y_pobre%>%head()
y_porbre%>%count()
y_porbre%>%count(s1)
y_pobre%>%count(s1)
y_pobre%>%count()
y_pobre%>%table()
predicciones$Predicho <- y_hat_in3
View(predicciones)
plot(predicciones$IngpcReal, predicciones$Predicho)
plot(predicciones$Predicho, predicciones$IngpcReal)
for (i in 1:length(lambdas_ridge)) {
l <- lambdas_ridge[i]
y_hat_out3 <- predicciones_ridge[, i]
r23 <- R2_Score(y_pred = y_hat_out3, y_true = y_train)
rmse3 <- RMSE(y_pred = y_hat_out3, y_true = y_train)
resultado <- data.frame(Modelo = "Ridge",
Muestra = "Dentro",
Lambda = i,
R2_Score = r23,
RMSE = rmse3)
resultados_ridge <- bind_rows(resultados_ridge, resultado)
}
ggplot(resultados_ridge, aes(x = Lambda, y = RMSE)) +
geom_point() +
geom_line() +
theme_test() +
scale_y_continuous(labels = scales::comma)
for (i in 1:length(lambdas_ridge)) {
l <- lambdas_ridge[i]
y_hat_out3 <- predicciones_ridge[, i]
r23 <- R2_Score(y_pred = y_hat_out3, y_true = y_train)
rmse3 <- RMSE(y_pred = y_hat_out3, y_true = y_train)
resultado <- data.frame(Modelo = "Ridge",
Muestra = "Dentro",
Lambda = l,
R2_Score = r23,
RMSE = rmse3)
resultados_ridge <- bind_rows(resultados_ridge, resultado)
}
ggplot(resultados_ridge, aes(x = Lambda, y = RMSE)) +
geom_point() +
geom_line() +
theme_test() +
scale_y_continuous(labels = scales::comma)
for (i in 1:length(lambdas_ridge)) {
l <- lambdas_ridge[i]
y_hat_out3 <- predicciones_ridge[, i]
r23 <- R2_Score(y_pred = y_hat_out3, y_true = y_train)
rmse3 <- RMSE(y_pred = y_hat_out3, y_true = y_train)
resultado <- data.frame(Modelo = "Ridge",
Muestra = "Dentro",
Lambda = l,
R2_Score = r23,
RMSE = rmse3)
resultados_ridge <- bind_rows(resultados_ridge, resultado)
}
ggplot(resultados_ridge, aes(x = Lambda, y = RMSE)) +
geom_point() +
geom_line() +
theme_test() +
scale_y_continuous(labels = scales::comma)
ggplot(resultados_ridge, aes(x = Lambda, y = R2_Score)) +
geom_point() +
geom_line() +
theme_test() +
scale_y_continuous(labels = scales::comma)
filtro <- resultados_ridge$RMSE == min(resultados_ridge$RMSE)
mejor_lambda_ridge <- resultados_ridge[filtro, "Lambda"]
# Guardamos el mejor Ridge
y_hat_in3<- predict.glmnet(modelo_ridge,
newx = as.matrix(X_train),
s = mejor_lambda_ridge)
y_pobre <- ifelse(y_hat_in3 <= predicciones$Lp, 1, 0)
predicciones$Predicho <- y_hat_in3
View(predicciones)
resultados_ridge$RMSE
ggplot(resultados_ridge, aes(x = Lambda, y = RMSE)) +
geom_point() +
geom_line() +
theme_test() +
scale_y_continuous(labels = scales::comma)
min(resultados_ridge$RMSE)
filtro
min(resultados_ridge$RMSE)
resultados_ridge$Lambda
filtro
mejor_lambda_ridge
# Guardamos el mejor Ridge
y_hat_in3<- predict.glmnet(modelo_ridge,
newx = as.matrix(X_train),
s = 300)
y_pobre <- ifelse(y_hat_in3 <= predicciones$Lp, 1, 0)
predicciones$Predicho <- y_hat_in3
View(predicciones)
# Guardamos el mejor Ridge
y_hat_in3<- predict.glmnet(modelo_ridge,
newx = as.matrix(X_train),
s = 300)
y_hat_in3
# Guardamos el mejor Ridge
y_hat_in3%>%head()<- predict.glmnet(modelo_ridge,
newx = as.matrix(X_train),
s = 300)
y_hat_in3%>%head()
mejor_lambda_ridge
resultados_ridge%>%head()
resultados_ridge <- data.frame()
for (i in 1:length(lambdas_ridge)) {
l <- lambdas_ridge[i]
y_hat_out3 <- predicciones_ridge[, i]
r23 <- R2_Score(y_pred = y_hat_out3, y_true = y_train)
rmse3 <- RMSE(y_pred = y_hat_out3, y_true = y_train)
resultado <- data.frame(Modelo = "Ridge",
Muestra = "Dentro",
Lambda = l,
R2_Score = r23,
RMSE = rmse3)
resultados_ridge <- bind_rows(resultados_ridge, resultado)
}
ggplot(resultados_ridge, aes(x = Lambda, y = RMSE)) +
geom_point() +
geom_line() +
theme_test() +
scale_y_continuous(labels = scales::comma)
resultados_ridge%>%head()
resultados_ridge%>%head()%>%sort(RMSE)
resultados_ridge%>%head()%>%sort(RMSE)
resultados_ridge%>%head()
