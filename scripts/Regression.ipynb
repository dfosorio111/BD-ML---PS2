{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "914795f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: widget. Using notebook instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import libraries\n",
    "%matplotlib notebook\n",
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import graphviz \n",
    "import shap\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, LogisticRegression\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16e43b",
   "metadata": {},
   "source": [
    "# Regresiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ae9fea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clase1</th>\n",
       "      <th>Clase2</th>\n",
       "      <th>P5000</th>\n",
       "      <th>P5010</th>\n",
       "      <th>P50902</th>\n",
       "      <th>P50903</th>\n",
       "      <th>P50904</th>\n",
       "      <th>P50905</th>\n",
       "      <th>P50906</th>\n",
       "      <th>...</th>\n",
       "      <th>prop_Desocupados_pet</th>\n",
       "      <th>prop_mujeres_total</th>\n",
       "      <th>Ingtotugarr</th>\n",
       "      <th>recibe_arriendos1</th>\n",
       "      <th>prop_cotiza</th>\n",
       "      <th>ppc</th>\n",
       "      <th>Valor_Arriendo</th>\n",
       "      <th>age2</th>\n",
       "      <th>log_ingtot</th>\n",
       "      <th>Pobre1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.310209</td>\n",
       "      <td>0.012543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.378393</td>\n",
       "      <td>-0.085933</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.855801</td>\n",
       "      <td>-0.877705</td>\n",
       "      <td>-0.059398</td>\n",
       "      <td>0.303971</td>\n",
       "      <td>13.527830</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.289483</td>\n",
       "      <td>0.012543</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.378393</td>\n",
       "      <td>-0.085933</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.107525</td>\n",
       "      <td>0.330174</td>\n",
       "      <td>-0.008577</td>\n",
       "      <td>-0.656062</td>\n",
       "      <td>14.285515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.289483</td>\n",
       "      <td>2.238883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.378393</td>\n",
       "      <td>0.274556</td>\n",
       "      <td>4498000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.855801</td>\n",
       "      <td>2.443962</td>\n",
       "      <td>-0.046692</td>\n",
       "      <td>-0.246199</td>\n",
       "      <td>15.319144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.909902</td>\n",
       "      <td>-1.100627</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.378393</td>\n",
       "      <td>-1.888376</td>\n",
       "      <td>1234453.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.034178</td>\n",
       "      <td>-0.877705</td>\n",
       "      <td>-0.033987</td>\n",
       "      <td>-0.790548</td>\n",
       "      <td>14.026139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.489637</td>\n",
       "      <td>0.012543</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.378393</td>\n",
       "      <td>0.815288</td>\n",
       "      <td>1173457.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.107525</td>\n",
       "      <td>0.330174</td>\n",
       "      <td>-0.033987</td>\n",
       "      <td>-0.560582</td>\n",
       "      <td>13.975466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clase1  Clase2     P5000     P5010  P50902  P50903  P50904  \\\n",
       "0           1       1       0 -0.310209  0.012543       0       0       0   \n",
       "1           2       1       0  1.289483  0.012543       1       0       0   \n",
       "2           3       1       0  1.289483  2.238883       0       0       0   \n",
       "3           4       1       0 -1.909902 -1.100627       0       1       0   \n",
       "4           5       1       0  0.489637  0.012543       0       1       0   \n",
       "\n",
       "   P50905  P50906  ...  prop_Desocupados_pet  prop_mujeres_total  Ingtotugarr  \\\n",
       "0       0       0  ...             -0.378393           -0.085933     750000.0   \n",
       "1       0       0  ...             -0.378393           -0.085933    1600000.0   \n",
       "2       0       0  ...             -0.378393            0.274556    4498000.0   \n",
       "3       0       0  ...             -0.378393           -1.888376    1234453.0   \n",
       "4       0       0  ...             -0.378393            0.815288    1173457.0   \n",
       "\n",
       "   recibe_arriendos1  prop_cotiza       ppc  Valor_Arriendo      age2  \\\n",
       "0                  0    -0.855801 -0.877705       -0.059398  0.303971   \n",
       "1                  0     0.107525  0.330174       -0.008577 -0.656062   \n",
       "2                  0    -0.855801  2.443962       -0.046692 -0.246199   \n",
       "3                  0     2.034178 -0.877705       -0.033987 -0.790548   \n",
       "4                  0     0.107525  0.330174       -0.033987 -0.560582   \n",
       "\n",
       "   log_ingtot  Pobre1  \n",
       "0   13.527830       0  \n",
       "1   14.285515       0  \n",
       "2   15.319144       0  \n",
       "3   14.026139       0  \n",
       "4   13.975466       0  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cargar la base dummyficada\n",
    "df_dummy = pd.read_csv('C:/Users/Diego/OneDrive/Documents/GitHub/BD-ML---PS2/data/dfdummy.csv')\n",
    "\n",
    "# cargar train-set con variables continuas escaladas\n",
    "train_s = pd.read_csv('C:/Users/Diego/OneDrive/Documents/GitHub/BD-ML---PS2/data/train_s.csv')\n",
    "# cargar test-set con variables continuas escaladas\n",
    "test_s = pd.read_csv('C:/Users/Diego/OneDrive/Documents/GitHub/BD-ML---PS2/data/tets_s.csv')\n",
    "\n",
    "# cargar train-set con tecnica de imbalance: undersampling de la clase mayoritaria (NO POBRE)\n",
    "train_s_under = pd.read_csv('C:/Users/Diego/OneDrive/Documents/GitHub/BD-ML---PS2/data/train_s_under.csv')\n",
    "\n",
    "train_s_under.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4dbee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar bases\n",
    "df_dummy = pd.read_csv('C:/Users/danie/OneDrive/Escritorio/Uniandes/PEG/Big Data and Machine Learning/BD-ML---PS2/data/dfdummy.csv')\n",
    "train_s = pd.read_csv('C:/Users/danie/OneDrive/Escritorio/Uniandes/PEG/Big Data and Machine Learning/BD-ML---PS2/data/train_s.csv')\n",
    "test_s = pd.read_csv('C:/Users/danie/OneDrive/Escritorio/Uniandes/PEG/Big Data and Machine Learning/BD-ML---PS2/data/tets_s.csv')\n",
    "train_s_under = pd.read_csv('C:/Users/danie/OneDrive/Escritorio/Uniandes/PEG/Big Data and Machine Learning/BD-ML---PS2/data/train_s_under.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "643e44f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clase2</th>\n",
       "      <th>P5000</th>\n",
       "      <th>P5010</th>\n",
       "      <th>P50902</th>\n",
       "      <th>P50903</th>\n",
       "      <th>P50904</th>\n",
       "      <th>P50905</th>\n",
       "      <th>P50906</th>\n",
       "      <th>Npersug</th>\n",
       "      <th>Depto8</th>\n",
       "      <th>...</th>\n",
       "      <th>no_parientes1</th>\n",
       "      <th>emp_pen1</th>\n",
       "      <th>prop_ocupados_pet</th>\n",
       "      <th>prop_Desocupados_pet</th>\n",
       "      <th>prop_mujeres_total</th>\n",
       "      <th>recibe_arriendos1</th>\n",
       "      <th>prop_cotiza</th>\n",
       "      <th>ppc</th>\n",
       "      <th>Valor_Arriendo</th>\n",
       "      <th>age2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.310209</td>\n",
       "      <td>0.012543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.230948</td>\n",
       "      <td>-0.378393</td>\n",
       "      <td>-0.085933</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.855801</td>\n",
       "      <td>-0.877705</td>\n",
       "      <td>-0.059398</td>\n",
       "      <td>0.303971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.289483</td>\n",
       "      <td>0.012543</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246213</td>\n",
       "      <td>-0.378393</td>\n",
       "      <td>-0.085933</td>\n",
       "      <td>0</td>\n",
       "      <td>0.107525</td>\n",
       "      <td>0.330174</td>\n",
       "      <td>-0.008577</td>\n",
       "      <td>-0.656062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.289483</td>\n",
       "      <td>2.238883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.541576</td>\n",
       "      <td>-0.378393</td>\n",
       "      <td>0.274556</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.855801</td>\n",
       "      <td>2.443962</td>\n",
       "      <td>-0.046692</td>\n",
       "      <td>-0.246199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.909902</td>\n",
       "      <td>-1.100627</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.230948</td>\n",
       "      <td>-0.378393</td>\n",
       "      <td>-1.888376</td>\n",
       "      <td>0</td>\n",
       "      <td>2.034178</td>\n",
       "      <td>-0.877705</td>\n",
       "      <td>-0.033987</td>\n",
       "      <td>-0.790548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.489637</td>\n",
       "      <td>0.012543</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246213</td>\n",
       "      <td>-0.378393</td>\n",
       "      <td>0.815288</td>\n",
       "      <td>0</td>\n",
       "      <td>0.107525</td>\n",
       "      <td>0.330174</td>\n",
       "      <td>-0.033987</td>\n",
       "      <td>-0.560582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clase2     P5000     P5010  P50902  P50903  P50904  P50905  P50906  \\\n",
       "0       0 -0.310209  0.012543       0       0       0       0       0   \n",
       "1       0  1.289483  0.012543       1       0       0       0       0   \n",
       "2       0  1.289483  2.238883       0       0       0       0       0   \n",
       "3       0 -1.909902 -1.100627       0       1       0       0       0   \n",
       "4       0  0.489637  0.012543       0       1       0       0       0   \n",
       "\n",
       "   Npersug  Depto8  ...  no_parientes1  emp_pen1  prop_ocupados_pet  \\\n",
       "0        2       0  ...              0         0           1.230948   \n",
       "1        4       0  ...              0         0           0.246213   \n",
       "2       15       1  ...              0         0          -0.541576   \n",
       "3        1       0  ...              0         0           1.230948   \n",
       "4        4       0  ...              0         0           0.246213   \n",
       "\n",
       "   prop_Desocupados_pet  prop_mujeres_total  recibe_arriendos1  prop_cotiza  \\\n",
       "0             -0.378393           -0.085933                  0    -0.855801   \n",
       "1             -0.378393           -0.085933                  0     0.107525   \n",
       "2             -0.378393            0.274556                  0    -0.855801   \n",
       "3             -0.378393           -1.888376                  0     2.034178   \n",
       "4             -0.378393            0.815288                  0     0.107525   \n",
       "\n",
       "        ppc  Valor_Arriendo      age2  \n",
       "0 -0.877705       -0.059398  0.303971  \n",
       "1  0.330174       -0.008577 -0.656062  \n",
       "2  2.443962       -0.046692 -0.246199  \n",
       "3 -0.877705       -0.033987 -0.790548  \n",
       "4  0.330174       -0.033987 -0.560582  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bases para clasificación\n",
    "# y_train yi obs/target es discreta. variable Pobre1[0,1]\n",
    "# x_train es todas las variables en x_test - y_target(pobre1)- log_ingtot -Ingtotugarr- Clase1- Lp  variables con multi colinealidad\n",
    "\n",
    "y_train = train_s_under['Pobre1']\n",
    "x_train = train_s_under.drop(['Unnamed: 0','Pobre1','log_ingtot','Ingtotugarr','Clase1','Lp'], axis=1) \n",
    "\n",
    "\n",
    "y_test = test_s['Pobre1']\n",
    "x_test = test_s.drop(['Unnamed: 0','Pobre1','log_ingtot','Ingtotugarr','Clase1','Lp'], axis=1) \n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f3e7212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        13.527830\n",
       "1        14.285515\n",
       "2        15.319144\n",
       "3        14.026139\n",
       "4        13.975466\n",
       "           ...    \n",
       "66082    13.307460\n",
       "66083    13.592370\n",
       "66084    12.988830\n",
       "66085    11.945800\n",
       "66086    13.158380\n",
       "Name: log_ingtot, Length: 66087, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bases para regresión\n",
    "# y_train yi obs/target es discreta. variable Pobre1[0,1]\n",
    "# x_train es todas las variables en x_test - y_target(pobre1)- log_ingtot -Ingtotugarr- Clase1- Lp  variables con multi colinealidad\n",
    "\n",
    "y_train = train_s_under['log_ingtot']\n",
    "x_train_lp = train_s_under['Lp']\n",
    "y_train_p = train_s_under['Pobre1']\n",
    "x_train = train_s_under.drop(['Unnamed: 0','Pobre1','log_ingtot','Ingtotugarr','Clase1','Lp'], axis=1) \n",
    "\n",
    "\n",
    "y_test = test_s['log_ingtot']\n",
    "y_test_p = test_s['Pobre1']\n",
    "x_test_lp = test_s['Lp']\n",
    "x_test = test_s.drop(['Unnamed: 0','Pobre1','log_ingtot','Ingtotugarr','Clase1','Lp'], axis=1) \n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9667a57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8228093270991269 0.8356798617846751 0.7776101956939784 0.5650756247259974 0.7801399659542273 0.7801399659542273 0.7788730266636453 0.6554162495431504\n"
     ]
    }
   ],
   "source": [
    "# crear LinearRegression() Regresion Lineal simple \n",
    "# fit/train ajustar el modelo a train-set\n",
    "\n",
    "linreg1 = LinearRegression().fit(x_train,y_train)\n",
    "\n",
    "\n",
    "# y_hat crear vectores de prediccion y_hat  en train-set y test-set\n",
    "y_hat_train = linreg1.predict(x_train)\n",
    "y_hat_test = linreg1.predict(x_test)\n",
    "\n",
    "# convertir y_hat en discreto\n",
    "\n",
    "y_hat_train_disc = np.exp(y_hat_train)\n",
    "y_hat_train_disc = (y_hat_train_disc/x_train['Npersug'])\n",
    "y_hat_train_resu = y_hat_train_disc <= x_train_lp\n",
    "y_hat_train_resu.astype(int)\n",
    "\n",
    "\n",
    "y_hat_test_disc = np.exp(y_hat_test)\n",
    "y_hat_test_disc = (y_hat_test_disc/x_test['Npersug'])\n",
    "y_hat_test_resu = y_hat_test_disc <= x_test_lp\n",
    "y_hat_test_resu.astype(int)\n",
    "\n",
    "\n",
    "# matriz de confusion\n",
    "confusion_train = confusion_matrix(y_train_p, y_hat_train_resu)\n",
    "confusion_test = confusion_matrix(y_test_p, y_hat_test_resu)\n",
    "\n",
    "\n",
    "# metricas de evaluacion\n",
    "\n",
    "train_acc = accuracy_score(y_train_p, y_hat_train_resu )\n",
    "test_acc = accuracy_score(y_test_p, y_hat_test_resu )\n",
    "\n",
    "train_prec =precision_score(y_train_p, y_hat_train_resu)\n",
    "test_prec =precision_score(y_test_p, y_hat_test_resu )\n",
    "\n",
    "train_recall = recall_score(y_train_p, y_hat_train_resu )\n",
    "test_recall = recall_score(y_test_p, y_hat_test_resu )\n",
    "\n",
    "train_f1 = f1_score(y_train_p, y_hat_train_resu )\n",
    "test_f1 = f1_score(y_test_p, y_hat_test_resu )\n",
    "\n",
    "\n",
    "\n",
    "#print(classification_report)\n",
    "print(train_acc, test_acc, train_prec, test_prec, train_recall, test_recall, train_f1, test_f1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0341470d",
   "metadata": {},
   "source": [
    "## Regularización: Ridge y Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21892d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "# RobustScaler  crear escalador Robusto\n",
    "scaler = RobustScaler()\n",
    "\n",
    "\n",
    "# estandarizar xi DESPUES de partir la base en train-set y test-set\n",
    "# ajustar escalador robusto con x_train\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# estandarizar x_train y x_test\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "# crear RidgeRegression ,fit/train ajustar modelo con train-set\n",
    "\n",
    "lridge = Ridge(random_state=0).fit(x_train_scaled, y_train)\n",
    "lridge\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "572fa6e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14784\\1167206050.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# crear GridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mgrid_lridge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlridge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mgrid_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'recall'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mgrid_lridge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Grid best parameter(max. recall): '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_lridge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1009\u001b[0m             \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m         )\n\u001b[1;32m-> 1011\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m         \u001b[1;31m# when X is sparse we only remove offset from y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m         X, y, X_offset, y_offset, X_scale = self._preprocess_data(\n\u001b[0m\u001b[0;32m    747\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[1;34m(X, y, fit_intercept, normalize, copy, sample_weight, return_mean, check_input)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmay_share_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# crear RidgeRegression\n",
    "# fit/train ajustar modelo con train-set\n",
    "lridge = Ridge(random_state=0).fit(x_train_scaled, y_train)\n",
    "lridge\n",
    "\n",
    "# grid de alpha_reg: parámetro de regularización\n",
    "alpha_reg = np.linspace(0,2,100)\n",
    "\n",
    "# crear grid de valores para hacer GridSerachCV de parametros optimos mediante validacion cruzada\n",
    "grid_values = {'alpha': alpha_reg }\n",
    "\n",
    "# crear GridSearchCV \n",
    "grid_lridge = GridSearchCV(lridge, param_grid= grid_values, scoring='recall')\n",
    "grid_lridge.fit(x_train_scaled,y_train)\n",
    "\n",
    "print('Grid best parameter(max. recall): ', grid_lridge.best_params_)\n",
    "print('Grid best score (recall): ' , grid_lridge.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "# cross-val manual\n",
    "recall_max=0\n",
    "accuracy_max=0\n",
    "prec_max=0\n",
    "f1_max=0\n",
    "\n",
    "\n",
    "for alpha_actual in alpha_reg:\n",
    "    \n",
    "    # crear modelo Ridge\n",
    "    lridge = Ridge(random_state=0,alpha=alpha_actual).fit(x_train_scaled,y_train)\n",
    "    \n",
    "    # crear y_hat de prediccines en train-set y test-set\n",
    "    y_hat_train_lridge = lridge.predict(x_train)\n",
    "    y_hat_test_lridge = lridge.predict(x_test)\n",
    "    \n",
    "    print(y_hat_train_lridge)\n",
    "    # metricas de evaluacion\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffeb3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat crear vectores de prediccion y_hat  en train-set y test-set\n",
    "y_hat_train = linreg1.predict(x_train)\n",
    "y_hat_test = linreg1.predict(x_test)\n",
    "\n",
    "# convertir y_hat en continuo\n",
    "\n",
    "y_hat_train_disc = np.exp(y_hat_train)\n",
    "y_hat_train_disc = (y_hat_train_disc/x_train['Npersug'])\n",
    "y_hat_train_resu = y_hat_train_disc <= x_train_lp\n",
    "y_hat_train_resu.astype(int)\n",
    "\n",
    "\n",
    "y_hat_test_disc = np.exp(y_hat_test)\n",
    "y_hat_test_disc = (y_hat_test_disc/x_test['Npersug'])\n",
    "y_hat_test_resu = y_hat_test_disc <= x_test_lp\n",
    "y_hat_test_resu.astype(int)\n",
    "\n",
    "\n",
    "# matriz de confusion\n",
    "confusion_train = confusion_matrix(y_train_p, y_hat_train_resu)\n",
    "confusion_test = confusion_matrix(y_test_p, y_hat_test_resu)\n",
    "\n",
    "# metricas de evaluacion\n",
    "train_acc = accuracy_score(y_train_p, y_hat_train_resu )\n",
    "test_acc = accuracy_score(y_test_p, y_hat_test_resu )\n",
    "\n",
    "train_prec =precision_score(y_train_p, y_hat_train_resu)\n",
    "test_prec =precision_score(y_test_p, y_hat_test_resu )\n",
    "\n",
    "train_recall = recall_score(y_train_p, y_hat_train_resu )\n",
    "test_recall = recall_score(y_test_p, y_hat_test_resu )\n",
    "\n",
    "train_f1 = f1_score(y_train_p, y_hat_train_resu )\n",
    "test_f1 = f1_score(y_test_p, y_hat_test_resu )\n",
    "\n",
    "\n",
    "\n",
    "#print(classification_report)\n",
    "print(train_acc, test_acc, train_prec, test_prec, train_recall, test_recall, train_f1, test_f1)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "print('Ridge regression linear model intercept: {}'\n",
    "     .format(linlasso.intercept_))\n",
    "print('Ridge regression linear model coeff:\\n{}'\n",
    "     .format(linlasso.coef_))\n",
    "print('Non-zero features: {}'\n",
    "     .format(np.sum(linlasso.coef_ != 0)))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linlasso.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(linlasso.score(X_test_scaled, y_test)))\n",
    "print('Features with non-zero weight (sorted by absolute magnitude):')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f488b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter(max. recall):  {'alpha': 0.0}\n",
      "Grid best score (recall):  nan\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression \n",
    "\n",
    "# RobustScaler  crear escalador Robusto\n",
    "scaler = RobustScaler()\n",
    "\n",
    "\n",
    "# estandarizar xi DESPUES de partir la base en train-set y test-set\n",
    "# ajustar escalador robusto con x_train\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# estandarizar x_train y x_test\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "# crear RidgeRegression ,fit/train ajustar modelo con train-set\n",
    "\n",
    "lasso = Lasso(random_state=0).fit(x_train_scaled, y_train)\n",
    "lasso\n",
    "\n",
    "alpha_reg = np.linspace(0,1,100)\n",
    "\n",
    "\n",
    "# crear grid de valores para hacer GridSerachCV de parametros optimos mediante validacion cruzada\n",
    "grid_values = {'alpha': alpha_reg }\n",
    "\n",
    "# crear GridSearchCV \n",
    "grid_lasso = GridSearchCV(lasso, param_grid= grid_values, scoring='recall')\n",
    "grid_lasso.fit(x_train_scaled,y_train)\n",
    "\n",
    "print('Grid best parameter(max. recall): ', grid_lasso.best_params_)\n",
    "print('Grid best score (recall): ' , grid_lasso.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc457bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat crear vectores de prediccion y_hat  en train-set y test-set\n",
    "y_hat_train = linreg1.predict(x_train)\n",
    "y_hat_test = linreg1.predict(x_test)\n",
    "\n",
    "# convertir y_hat en continuo\n",
    "\n",
    "y_hat_train_disc = np.exp(y_hat_train)\n",
    "y_hat_train_disc = (y_hat_train_disc/x_train['Npersug'])\n",
    "y_hat_train_resu = y_hat_train_disc <= x_train_lp\n",
    "y_hat_train_resu.astype(int)\n",
    "\n",
    "\n",
    "y_hat_test_disc = np.exp(y_hat_test)\n",
    "y_hat_test_disc = (y_hat_test_disc/x_test['Npersug'])\n",
    "y_hat_test_resu = y_hat_test_disc <= x_test_lp\n",
    "y_hat_test_resu.astype(int)\n",
    "\n",
    "\n",
    "# matriz de confusion\n",
    "confusion_train = confusion_matrix(y_train_p, y_hat_train_resu)\n",
    "confusion_test = confusion_matrix(y_test_p, y_hat_test_resu)\n",
    "\n",
    "# metricas de evaluacion\n",
    "train_acc = accuracy_score(y_train_p, y_hat_train_resu )\n",
    "test_acc = accuracy_score(y_test_p, y_hat_test_resu )\n",
    "\n",
    "train_prec =precision_score(y_train_p, y_hat_train_resu)\n",
    "test_prec =precision_score(y_test_p, y_hat_test_resu )\n",
    "\n",
    "train_recall = recall_score(y_train_p, y_hat_train_resu )\n",
    "test_recall = recall_score(y_test_p, y_hat_test_resu )\n",
    "\n",
    "train_f1 = f1_score(y_train_p, y_hat_train_resu )\n",
    "test_f1 = f1_score(y_test_p, y_hat_test_resu )\n",
    "\n",
    "\n",
    "#print(classification_report)\n",
    "print(train_acc, test_acc, train_prec, test_prec, train_recall, test_recall, train_f1, test_f1)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "print('lasso regression linear model intercept: {}'\n",
    "     .format(linlasso.intercept_))\n",
    "print('lasso regression linear model coeff:\\n{}'\n",
    "     .format(linlasso.coef_))\n",
    "print('Non-zero features: {}'\n",
    "     .format(np.sum(linlasso.coef_ != 0)))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linlasso.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(linlasso.score(X_test_scaled, y_test)))\n",
    "print('Features with non-zero weight (sorted by absolute magnitude):')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca669e00",
   "metadata": {},
   "source": [
    "# Regresion Logistica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "380ed1fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RobustScaler  crear escalador Robusto\n",
    "scaler = RobustScaler()\n",
    "\n",
    "\n",
    "# estandarizar xi DESPUES de partir la base en train-set y test-set\n",
    "# ajustar escalador robusto con x_train\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# estandarizar x_train y x_test\n",
    "#x_train_scaled = scaler.transform(x_train)\n",
    "#x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# crear modelo Logistica (MLE para ajustar parametros/betas)\n",
    "log = LogisticRegression().fit(x_train,y_train_p)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456a6446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
